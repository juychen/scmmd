{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import snapatac2 as snap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utils\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_dir ='/data2st1/junyi/output/atac0416/dar/motif/region_nt'\n",
    "# for ct in df_DAR_mememto['ctname'].unique():\n",
    "#     for condition in df_inner['condition'].unique():\n",
    "#         df_sub = df_inner[(df_inner['ctname'] == ct) & (df_inner['condition'] == condition)]\n",
    "#         if len(df_sub) == 0:\n",
    "#             continue\n",
    "#         df_sub[\"names\"].str.split(r'[:-]', expand=True).to_csv(f'{out_dir}/{ct}_{condition}_memento.bed', sep='\\t', header=False, index=False)\n",
    "# files = glob.glob('/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/*vs*.bed')\n",
    "# for file in files:\n",
    "#     df = pd.read_csv(file, sep='\\t', header=None)\n",
    "#     df.columns = ['chr', 'start', 'end', 'names']\n",
    "#     df['chr'] = 'chr'+ df['chr'].astype(str)\n",
    "#     df.to_csv(file, sep='\\t', header=False, index=False)\n",
    "#     filename = os.path.basename(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pycistarget', 'cistarget', '--cistarget_db_fname', '/data2st1/junyi/scenic/mouse/motif/mm10_screen_v10_clust.regions_vs_motifs.rankings.feather', '--bed_fname', '/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/merged_unique.bed', '--species', 'mus_musculus', '--auc_threshold', '0.005', '--nes_threshold', '3.0', '--rank_threshold', '0.05', '--path_to_motif_annotations', '/data2st1/junyi/scenic/mouse/motif/motifs-v10nr_clust-nr.mgi-m0.001-o0.0.tbl', '--output_folder', '/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/cistarget/', '--write_html']\n",
      "2025-07-26 08:20:07,522 cisTarget    INFO     Reading cisTarget database\n",
      "2025-07-26 08:27:16,286 cisTarget    INFO     Running cisTarget for merged_unique which has 11130060 regions\n",
      "2025-07-26 08:31:13,625 cisTarget    INFO     Annotating motifs for merged_unique\n",
      "2025-07-26 08:31:21,274 cisTarget    INFO     Getting cistromes for merged_unique\n"
     ]
    }
   ],
   "source": [
    "files = glob.glob('/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/merged_unique.bed')\n",
    "for filename in files:\n",
    "    command_str = ['pycistarget','cistarget','--cistarget_db_fname','/data2st1/junyi/scenic/mouse/motif/mm10_screen_v10_clust.regions_vs_motifs.rankings.feather'\n",
    "                   ,'--bed_fname',filename,'--species','mus_musculus','--auc_threshold','0.005','--nes_threshold','3.0','--rank_threshold','0.05'\n",
    "                   ,'--path_to_motif_annotations','/data2st1/junyi/scenic/mouse/motif/motifs-v10nr_clust-nr.mgi-m0.001-o0.0.tbl'\n",
    "                   ,'--output_folder','/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/cistarget/','--write_html']\n",
    "    print(command_str)\n",
    "    subprocess.run(command_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = glob.glob(f'/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/cistarget/*merged_unique*.hdf5')\n",
    "df_report = utils.conclude_pycistargets(flist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tfs = df_report.TFs.astype(str).str.replace(r'[{}\\' ]', '', regex=True).replace('nan', '', regex=True).str.strip(',').str.replace(',', '/').str.replace('//','/')\n",
    "df_report['TFs'] = processed_tfs\n",
    "# For the column of TFs, split the string by '/' and explode the DataFrame\n",
    "df_report['TFss'] = df_report['TFs'].str.split('/')\n",
    "df_explode = df_report.explode('TFss', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode.to_csv('/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/cistarget/cistarget_dmr_merged_unique_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = 'up'\n",
    "region = 'AMY'\n",
    "gender = 'M'\n",
    "df_reports = pd.DataFrame()\n",
    "for condition in ['up', 'down']:\n",
    "    for region in ['AMY', 'HIP', 'PFC']:\n",
    "        for gender in ['M', 'F']:\n",
    "            flist = glob.glob(f'/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/cistarget/*{gender}C*-{region}*{condition}*.hdf5')\n",
    "            df_report = utils.conclude_pycistargets(flist)  \n",
    "            df_report['condition'] = condition\n",
    "            df_report['brain_region'] = region\n",
    "            df_report['gender'] = gender\n",
    "            df_reports = pd.concat([df_reports, df_report], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove replace symbols include ' ' or '{' or '}' or \"'\" or to ''\n",
    "# remove  nan\n",
    "# stride valus if the first and last character is ,\n",
    "processed_tfs = df_reports.TFs.astype(str).str.replace(r'[{}\\' ]', '', regex=True).replace('nan', '', regex=True).str.strip(',').str.replace(',', '/').str.replace('//','/')\n",
    "df_reports['TFs'] = processed_tfs\n",
    "# For the column of TFs, split the string by '/' and explode the DataFrame\n",
    "df_reports['TFss'] = df_reports['TFs'].str.split('/')\n",
    "df_explode = df_reports.explode('TFss', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode.to_csv('/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/cistarget/cistarget_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_related = ['/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/dmr_related_region.bed']\n",
    "for filename in files_related:\n",
    "    command_str = ['pycistarget','cistarget','--cistarget_db_fname','/data2st1/junyi/scenic/mouse/motif/mm10_screen_v10_clust.regions_vs_motifs.rankings.feather'\n",
    "                   ,'--bed_fname',filename,'--species','mus_musculus','--auc_threshold','0.005','--nes_threshold','3.0','--rank_threshold','0.05'\n",
    "                   ,'--path_to_motif_annotations','/data2st1/junyi/scenic/mouse/motif/motifs-v10nr_clust-nr.mgi-m0.001-o0.0.tbl'\n",
    "                   ,'--output_folder','/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/cistarget/','--write_html']\n",
    "    print(command_str)\n",
    "    subprocess.run(command_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reports = utils.conclude_pycistargets(['/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/cistarget/motif_enrichment_cistarget_dmr_related_region.hdf5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_tfs = df_reports.TFs.astype(str).str.replace(r'[{}\\' ]', '', regex=True).replace('nan', '', regex=True).str.strip(',').str.replace(',', '/').str.replace('//','/')\n",
    "df_reports['TFs'] = processed_tfs\n",
    "# For the column of TFs, split the string by '/' and explode the DataFrame\n",
    "df_reports['TFss'] = df_reports['TFs'].str.split('/')\n",
    "df_explode = df_reports.explode('TFss', ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explode.to_csv('/data1st2/hannan_25/data/Nanopore_process/nanopore_08_differential/summary/dmr_sets/cistarget/cistarget_related_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ct in df_inner['ctname'].unique():\n",
    "    for condition in df_inner['condition'].unique():\n",
    "        try:\n",
    "            flist = glob.glob(f'/data2st1/junyi/output/atac0416/dar/motif/region_nt/*{ct}*{condition}*_inner.hdf5')\n",
    "            df_report = utils.conclude_pycistargets(flist)  \n",
    "            df_report_annotation = utils.annotate_region(df_report,region_col='region', bedfile='/data2st1/junyi/generegion_vM23/genebody_selected.bed')\n",
    "            df_report_annotation.to_csv(f'/data2st1/junyi/output/atac0416/dar/motif/region_nt/{ct}_{condition}_inner_region_TF.csv', index=False)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ct} and {condition}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_all_TFs = pd.DataFrame()\n",
    "for ct in df_DAR_mememto['ctname'].unique():\n",
    "    for condition in df_DAR_mememto['condition'].unique():\n",
    "        try:\n",
    "            #flist = glob.glob(f'/data2st1/junyi/output/atac0416/dar/motif/region_nt/*{ct}*{condition}*_memento.hdf5')\n",
    "            #df_report = utils.conclude_pycistargets(flist)  \n",
    "            #df_report_annotation = utils.annotate_region(df_report,region_col='region', bedfile='/data2st1/junyi/generegion_vM23/genebody_selected.bed')\n",
    "            #df_report.to_csv(f'/data2st1/junyi/output/atac0416/dar/motif/region_nt/{ct}_{condition}_memento_TF.csv', index=False)\n",
    "            df_test= pd.read_csv(f'/data2st1/junyi/output/atac0416/dar/motif/region_nt/{ct}_{condition}_memento_TF.csv')\n",
    "            df_test['TFs'] = df_test['TFs'].str.replace(r'[\"\\'}{}]|,?\\s*nan\\s*,?', '', regex=True).str.replace(r' ', '', regex=True).str.strip(\",\")\n",
    "            df_join_TFs=df_test[['region','TFs']].groupby(['region']).aggregate(\n",
    "                lambda x: \"/\".join(                        # Join aggregated values with '/'\n",
    "                    sorted(\n",
    "                        set(                                          # Keep unique values\n",
    "                            item for sublist in x.str.split(\",\")      # Split each string by '.'\n",
    "                            for item in sublist                       # Flatten the split lists\n",
    "                        )# Remove empty strings\n",
    "                    )\n",
    "                )\n",
    "            ).reset_index()\n",
    "            df_join_TFs[\"TFs\"]=df_join_TFs.TFs.str.strip('/')\n",
    "\n",
    "            df_join_TFs[\"motifs\"]=df_test[['region','motif']].groupby(['region']).aggregate(\n",
    "                lambda x:'/'.join(x)\n",
    "            ).reset_index()[\"motif\"]\n",
    "            df_join_TFs[\"ctname\"]=\"_\".join(df_test.key[0].split('_')[:2])\n",
    "            df_join_TFs[\"condition\"] = df_test.key[0].split('_')[2]\n",
    "            df_join_TFs[\"method\"] = df_test.key[0].split('_')[3]\n",
    "            df_join_all_TFs = pd.concat([df_join_all_TFs, df_join_TFs], axis=0, ignore_index=True)\n",
    "            #df_join_TFs.to_csv(f'/data2st1/junyi/output/atac0416/dar/motif/region_nt/{ct}_{condition}_memento_TF_join.csv', index=False)\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {ct} and {condition}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_all_TFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated_TFs = utils.annotate_region(df_join_all_TFs,region_col='region', bedfile='/data2st1/junyi/generegion_vM23/genebody_selected.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated_TFs['brain_region'] = df_annotated_TFs['ctname'].str.split(r'[_]').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotated_TFs.to_csv(f'/data2st1/junyi/output/atac0416/dar/motif/region_nt/motif_memento_TFs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in files:\n",
    "    df_dar  = pd.read_csv(filename,index_col=0)\n",
    "    experimentname = re.split(r'[./]', filename)[-2]\n",
    "    experimentname\n",
    "    folder_name = os.path.dirname(filename)\n",
    "    df_dar_filtered = df_dar[(df_dar['pvals']<0.05) & (df_dar['logfoldchanges']>0) ]\n",
    "    df_dar_filtered.sort_values(by='logfoldchanges',ascending=False,inplace=True)\n",
    "    # For liftover\n",
    "\n",
    "    temp_df = df_dar_filtered.names.str.split(r'[ ,!\\-;:|]',expand=True)\n",
    "    temp_df['ID'] = temp_df.index\n",
    "    temp_df.to_csv(f\"{folder_name}/{experimentname}_DAR.bed\",header=False,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# files = glob.glob('/data2st1/junyi/output/motif/ALL_*_wilcoxon_DAR.bed')\n",
    "# for filename in files:\n",
    "#     experimentname = re.split(r'[./]', filename)[-2]\n",
    "#     folder_name = os.path.dirname(filename)\n",
    "\n",
    "#     #!/home/junyichen/liftOver /data2st1/junyi/output/motif/PFC_Neuron_MW_wilcoxon_DAR.bed /data2st1/junyi/mm39ToMm10.over.chain.gz /data2st1/junyi/output/motif/PFC_Neuron_MW_wilcoxon_DAR_lifted.bed /data2st1/junyi/output/motif/PFC_Neuron_MW_wilcoxon_DAR_unmap.bed\n",
    "\n",
    "#     command_str = f\"/home/junyichen/liftOver {filename} /data2st1/junyi/mm39ToMm10.over.chain.gz {folder_name}/{experimentname}_lifted.bed {folder_name}/{experimentname}_unmap.bed\"\n",
    "#     print(command_str)\n",
    "#     subprocess.run(command_str, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/data2st1/junyi/output/motif/ALL_*_wilcoxon_DAR_lifted.bed')\n",
    "for filename in files:\n",
    "    destname = filename.replace(\"_lifted.bed\",\"_lifted_sorted.bed\")\n",
    "    #!sort -k1,1 -k2,2n {filename} > {destname}\n",
    "    command_str = f\"sort -k1,1 -k2,2n {filename} > {destname}\"\n",
    "    print(command_str)\n",
    "    subprocess.run(command_str, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sort -k1,1 -k2,2n /data2st1/junyi/output/motif/HIP_Neuron_MC_wilcoxon_DAR_lifted.bed > /data2st1/junyi/output/motif/HIP_Neuron_MC_wilcoxon_DAR_lifted_sorted.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sort -k1,1 -k2,2n /data2st1/junyi/output/motif/PFC_Neuron_MC_wilcoxon_DAR_lifted.bed > /data2st1/junyi/output/motif/PFC_Neuron_MC_wilcoxon_DAR_lifted_sorted.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !bedtools closest -a /data2st1/junyi/output/motif/PFC_Neuron_MC_wilcoxon_DAR_lifted_sorted.bed -b /data2st1/junyi/output/motif/genebody_selected_sorted.bed -D ref > /data2st1/junyi/output/motif/PFC_Neuron_MC_wilcoxon_DAR_gene.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !bedtools closest -a /data2st1/junyi/output/motif/HIP_Neuron_MC_wilcoxon_DAR_lifted_sorted.bed -b /data2st1/junyi/output/motif/genebody_selected_sorted.bed -D ref > /data2st1/junyi/output/motif/HIP_Neuron_MC_wilcoxon_DAR_gene.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/data2st1/junyi/output/motif/ALL_*_wilcoxon_DAR_lifted.bed')\n",
    "for filename in files:\n",
    "    command_str = ['pycistarget','cistarget','--cistarget_db_fname','/data2st1/junyi/scenic/mouse/motif/mm10_screen_v10_clust.regions_vs_motifs.rankings.feather'\n",
    "                   ,'--bed_fname',filename,'--species','mus_musculus','--auc_threshold','0.005','--nes_threshold','3.0','--rank_threshold','0.05'\n",
    "                   ,'--path_to_motif_annotations','/data2st1/junyi/scenic/mouse/motif/motifs-v10nr_clust-nr.mgi-m0.001-o0.0.tbl'\n",
    "                   ,'--output_folder','/data2st1/junyi/output/motif/','--write_html']\n",
    "    print(command_str)\n",
    "    subprocess.run(command_str)\n",
    "    \n",
    "# !pycistarget cistarget --cistarget_db_fname '/data2st1/junyi/scenic/mouse/motif/mm10_screen_v10_clust.regions_vs_motifs.rankings.feather' \\\n",
    "# --bed_fname '/data2st1/junyi/output/motif/AMY_Neuron_MC_wilcoxon_DAR_lifted.bed' \\\n",
    "# --species 'mus_musculus' \\\n",
    "# --auc_threshold 0.005 \\\n",
    "# --nes_threshold 3.0 \\\n",
    "# --rank_threshold 0.05 \\\n",
    "# --path_to_motif_annotations '/data2st1/junyi/scenic/mouse/motif/motifs-v10nr_clust-nr.mgi-m0.001-o0.0.tbl' \\\n",
    "# --output_folder '/data2st1/junyi/output/motif/' \\\n",
    "# --write_html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "dict_table = {}\n",
    "cell_types = ['Neuron','Astro-Epen','Vascular','Immune','OPC-Oligo']\n",
    "for celltype in cell_types:\n",
    "    with h5py.File(f'/data2st1/junyi/output/motif/motif_enrichment_cistarget_ALL_{celltype}_wilcoxon_DAR_lifted.hdf5', 'r') as f:\n",
    "        # Open the HDF5 file\n",
    "        # List all groups and datasets in the file\n",
    "        print(\"Keys in the file:\", list(f.keys()))\n",
    "        \n",
    "\n",
    "        # # Access a specific dataset\n",
    "        expname = f'ALL_{celltype}_wilcoxon_DAR_lifted'\n",
    "        dataset = f[expname]  # Replace with your dataset name\n",
    "        # print(\"Shape of the dataset:\", dataset.shape)\n",
    "        # print(\"Data type of the dataset:\", dataset.dtype)\n",
    "        dict_dataset = {}\n",
    "        #region = f[expname]['motif_hits']['region_set']['metacluster_33.8'][0:10]\n",
    "\n",
    "        table = f[expname]['motif_enrichment']['table'][:]\n",
    "        for key in dataset.keys():\n",
    "            dict_dataset[key] = dataset[key]\n",
    "        # print(\"Data:\", data)\n",
    "        dict_table[expname] = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys in dict_table.keys():\n",
    "    print(keys)\n",
    "    print(dict_table[keys][:5])\n",
    "    #Astro : id, orthology, direcrt, id, msimilarity,logo\n",
    "    #Neuron : id,logo,orthology, id, direct, msimilarity\n",
    "    #Vascular : id,logo,orthology,msimilarity,id, direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_table = []\n",
    "list_key = []\n",
    "list_TFs = []\n",
    "\n",
    "df_TF_celltype = pd.DataFrame()\n",
    "\n",
    "for key in dict_table.keys():\n",
    "    data = dict_table[key]\n",
    "    for row in data:\n",
    "        list_table.append(row[0].decode('utf-8'))\n",
    "        list_key.append(key)\n",
    "        TFs_tmp=[]\n",
    "        for i in range(1, len(row)-2):\n",
    "            if 'img' in row[i][0].decode('utf-8') or 'wilcoxon' in row[i][0].decode('utf-8'):\n",
    "                continue\n",
    "            TFs_tmp+=([ tf.decode('utf-8') for tf in row[i]])\n",
    "\n",
    "        df_tfs = pd.DataFrame({'TF':\",\".join(TFs_tmp).split(',')})\n",
    "        df_tfs['NES'] = row[-2][0]\n",
    "        df_tfs['AUC'] = row[-2][1]\n",
    "        df_tfs['Rank'] = row[-2][2]\n",
    "        df_tfs['celltype.L1'] = key.split('_')[1]\n",
    "        df_tfs['id'] = row[0].decode('utf-8')\n",
    "\n",
    "        list_TFs.append(set(TFs_tmp))\n",
    "        df_TF_celltype = pd.concat([df_TF_celltype,df_tfs],axis=0)\n",
    "        \n",
    "df_TF = pd.DataFrame({'TF':list_table,'key':list_key,'TFs':list_TFs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TF_celltype.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TF_celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RSS = pd.read_csv(\"/home/junyichen/code/scmmd/data/RSS_Score(only pos).csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RSS['TF']=df_RSS['Topic'].str.replace('[()+]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_to_category = {\n",
    "    # Astro-Epen\n",
    "    'Astro-Gfaphigh': 'Astro-Epen',\n",
    "    'Astro-TE': 'Astro-Epen',\n",
    "    \n",
    "    # Immune\n",
    "    'Microglia': 'Immune',\n",
    "    'PVM': 'Immune',\n",
    "    \n",
    "    # Neuron\n",
    "    'L2/3 IT': 'Neuron',\n",
    "    'L4/5 IT': 'Neuron',\n",
    "    'L5 ET': 'Neuron',\n",
    "    'L6 CT': 'Neuron',\n",
    "    'L6 IT': 'Neuron',\n",
    "    'L6b': 'Neuron',\n",
    "    'Lamp5 GABA': 'Neuron',\n",
    "    'Pvalb GABA': 'Neuron',\n",
    "    'Pvalb Vipr2 GABA': 'Neuron',\n",
    "    'Sst GABA': 'Neuron',\n",
    "    'Vip GABA': 'Neuron',\n",
    "    \n",
    "    # OPC-Oligo\n",
    "    'COP': 'OPC-Oligo',\n",
    "    'MFOL': 'OPC-Oligo',\n",
    "    'MOL': 'OPC-Oligo',\n",
    "    'NFOL': 'OPC-Oligo',\n",
    "    'NP': 'OPC-Oligo',\n",
    "    'OPC': 'OPC-Oligo',\n",
    "    \n",
    "    # Vascular\n",
    "    'Arachnoid barrier cell': 'Vascular',\n",
    "    'Car3': 'Vascular',\n",
    "    'Endothelial cell': 'Vascular',\n",
    "    'Pericyte': 'Vascular',\n",
    "    'VLMC': 'Vascular'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RSS['celltype.L1'] = df_RSS['celltype.L2'].map(cell_to_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TF_celltype.groupby(['celltype.L1']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_RSS.groupby(['celltype.L1']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_RSS.merge(df_TF_celltype,left_on=['TF','celltype.L1'],right_on=['TF','celltype.L1'],how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.sort_values(by='RSS',ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.drop_duplicates(set(['TF','celltype.L1']),keep='first').to_csv('/data2st1/junyi/output/motif/TF_RSS.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.groupby('celltype.L1').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.crosstab(df_merged['celltype'],df_merged['celltype.L1'],values=df_merged['RSS'],aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_merged['celltype']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/data2st1/junyi/output/motif/ALL_*_wilcoxon_DAR_lifted_sorted.bed')\n",
    "for filename in files:\n",
    "    destname = filename.replace(\"_lifted_sorted.bed\",\"_lifted_sorted_gene.bed\")\n",
    "    command_str = f\"bedtools closest -a {filename} -b /data2st1/junyi/output/motif/genebody_selected_sorted.bed -D ref > {destname}\"\n",
    "    print(command_str)\n",
    "    subprocess.run(command_str, shell=True)\n",
    "# !bedtools closest -a /data2st1/junyi/output/motif/PFC_Neuron_MC_wilcoxon_DAR_lifted_sorted.bed -b /data2st1/junyi/output/motif/genebody_selected_sorted.bed -D ref > /data2st1/junyi/output/motif/PFC_Neuron_MC_wilcoxon_DAR_gene.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pycistarget cistarget --cistarget_db_fname '/data2st1/junyi/scenic/mouse/motif/mm10_screen_v10_clust.regions_vs_motifs.rankings.feather' \\\n",
    "--bed_fname '/data2st1/junyi/output/motif/AMY_Neuron_MC_wilcoxon_DAR_lifted.bed' \\\n",
    "--species 'mus_musculus' \\\n",
    "--auc_threshold 0.005 \\\n",
    "--nes_threshold 3.0 \\\n",
    "--rank_threshold 0.05 \\\n",
    "--path_to_motif_annotations '/data2st1/junyi/scenic/mouse/motif/motifs-v10nr_clust-nr.mgi-m0.001-o0.0.tbl' \\\n",
    "--output_folder '/data2st1/junyi/output/motif/' \\\n",
    "--write_html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/data2st1/junyi/output/motif/*MW*wilcoxon.csv')\n",
    "for filename in files:\n",
    "    df_dar  = pd.read_csv(filename,index_col=0)\n",
    "    experimentname = re.split(r'[./]', filename)[-2]\n",
    "    experimentname\n",
    "    folder_name = os.path.dirname(filename)\n",
    "    df_dar_filtered = df_dar[(df_dar['pvals']<0.05) & (df_dar['logfoldchanges']>0) ]\n",
    "    df_dar_filtered.sort_values(by='logfoldchanges',ascending=False,inplace=True)\n",
    "    # For liftover\n",
    "    df_dar_filtered.names.str.split(r'[ ,!\\-;:|]',expand=True).to_csv(f\"{folder_name}/{experimentname}_DAR.bed\",header=False,index=False,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/data2st1/junyi/output/motif/*MW*wilcoxon_DAR.bed')\n",
    "for filename in files:\n",
    "    experimentname = re.split(r'[./]', filename)[-2]\n",
    "    folder_name = os.path.dirname(filename)\n",
    "\n",
    "    #!/home/junyichen/liftOver /data2st1/junyi/output/motif/PFC_Neuron_MW_wilcoxon_DAR.bed /data2st1/junyi/mm39ToMm10.over.chain.gz /data2st1/junyi/output/motif/PFC_Neuron_MW_wilcoxon_DAR_lifted.bed /data2st1/junyi/output/motif/PFC_Neuron_MW_wilcoxon_DAR_unmap.bed\n",
    "\n",
    "    command_str = f\"/home/junyichen/liftOver {filename} /data2st1/junyi/mm39ToMm10.over.chain.gz {folder_name}/{experimentname}_lifted.bed {folder_name}/{experimentname}_unmap.bed\"\n",
    "    print(command_str)\n",
    "    subprocess.run(command_str, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/data2st1/junyi/output/motif/*MW*wilcoxon_DAR_lifted.bed')\n",
    "for filename in files:\n",
    "    destname = filename.replace(\"_lifted.bed\",\"_lifted_sorted.bed\")\n",
    "    #!sort -k1,1 -k2,2n {filename} > {destname}\n",
    "    command_str = f\"sort -k1,1 -k2,2n {filename} > {destname}\"\n",
    "    print(command_str)\n",
    "    subprocess.run(command_str, shell=True)\n",
    "files = glob.glob('/data2st1/junyi/output/motif/*MW*wilcoxon_DAR_lifted_sorted.bed')\n",
    "for filename in files:\n",
    "    destname = filename.replace(\"_lifted_sorted.bed\",\"_lifted_sorted_gene.bed\")\n",
    "    command_str = f\"bedtools closest -a {filename} -b /data2st1/junyi/output/motif/genebody_selected_sorted.bed -D ref > {destname}\"\n",
    "    print(command_str)\n",
    "    subprocess.run(command_str, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyliftover import LiftOver\n",
    "# lo = LiftOver('/data2st1/junyi/mm10ToMm39.over.chain.gz')\n",
    "# lo.convert_coordinate('chr1', 1000000, '-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_frame = pd.DataFrame()\n",
    "files = glob.glob('/data2st1/junyi/output/motif/*MW*wilcoxon_DAR_lifted_sorted_gene.bed')\n",
    "for filename in files:\n",
    "    experimentname = re.split(r'[./]', filename)[-2]\n",
    "    region = re.split(r'_',experimentname)[0]\n",
    "    celltype = re.split(r'_',experimentname)[1]\n",
    "    condition = re.split(r'_',experimentname)[2]\n",
    "    try:\n",
    "        df = pd.read_csv(filename,sep='\\t',header=None)\n",
    "    except:\n",
    "        continue\n",
    "    df.columns = ['chrom','start','end','chrom2','start2','end2','score','starnd','gene_name','gene_id','annotation','distance']\n",
    "    df['region'] = region\n",
    "    df['celltype'] = celltype\n",
    "    df['condition'] = condition\n",
    "    df['name'] = df['chrom'] + ':' + df['start'].astype(str) + '-' + df['end'].astype(str)\n",
    "    # df_score = pd.read_csv(f\"/data2st1/junyi/output/motif/{region}_{celltype}_{condition}_wilcoxon.csv\",index_col=0)\n",
    "    # df['logfoldchanges'] = df_score.set_index('names').loc[df['name'],'logfoldchanges'].values\n",
    "    # df['pvals'] = df_score.set_index('names').loc[df['name'],'pvals'].values\n",
    "    result_frame = pd.concat([result_frame,df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=result_frame, x='celltype', hue='region', dodge=False, palette='Set2',)\n",
    "ax.set_ylim(0,6000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep1=result_frame.sort_values(by='starnd',ascending=True).drop_duplicates(subset=['chrom','start','end'])\n",
    "keep1['generegion'] = 'genebody'\n",
    "#keep1.loc[keep1['distance']<0,'generegion'] = 'downstream'\n",
    "promoter = keep1.loc[(keep1['distance']>0) & (keep1['distance']<=2000) & (keep1['starnd']=='+')].index\n",
    "distal = keep1.loc[(keep1['distance']>0) & (keep1['distance']>=2000) & (keep1['starnd']=='+')].index\n",
    "keep1.loc[promoter,'generegion'] = 'promoter'\n",
    "keep1.loc[distal,'generegion'] = 'distal'\n",
    "\n",
    "promoter = keep1.loc[(keep1['distance']<0) & (keep1['distance']>=-2000) & (keep1['starnd']=='-')].index\n",
    "distal = keep1.loc[(keep1['distance']<0) & (keep1['distance']<=-2000) & (keep1['starnd']=='-')].index\n",
    "keep1.loc[promoter,'generegion'] = 'promoter'\n",
    "keep1.loc[distal,'generegion'] = 'distal'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep1=keep1.loc[keep1['start2']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep1.sort_values(by='starnd',ascending=True).drop_duplicates(subset=['chrom','start','end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(data=keep1, x='celltype', hue='generegion', dodge=False, palette='Set2',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/data2st1/junyi/output/motif/AMY_Neuron_MC_wilcoxon.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert hg38 to hg19\n",
    "# !/home/junyichen/liftOver /data2st1/junyi/output/motif/HIP_Neuron_MW_wilcoxon_DAR.bed /data2st1/junyi/mm39ToMm10.over.chain.gz /data2st1/junyi/output/motif/HIP_Neuron_MW_wilcoxon_DAR_lifted.bed /data2st1/junyi/output/motif/HIP_Neuron_MW_wilcoxon_DAR_unmap.bed\n",
    "# !/home/junyichen/liftOver /data2st1/junyi/output/motif/PFC_Neuron_MW_wilcoxon_DAR.bed /data2st1/junyi/mm39ToMm10.over.chain.gz /data2st1/junyi/output/motif/PFC_Neuron_MW_wilcoxon_DAR_lifted.bed /data2st1/junyi/output/motif/PFC_Neuron_MW_wilcoxon_DAR_unmap.bed\n",
    "# !/home/junyichen/liftOver /data2st1/junyi/output/motif/AMY_Neuron_MW_wilcoxon_DAR.bed /data2st1/junyi/mm39ToMm10.over.chain.gz /data2st1/junyi/output/motif/AMY_Neuron_MW_wilcoxon_DAR_lifted.bed /data2st1/junyi/output/motif/AMY_Neuron_MW_wilcoxon_DAR_unmap.bed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pycistarget cistarget --cistarget_db_fname '/data2st1/junyi/scenic/mouse/motif/mm10_screen_v10_clust.regions_vs_motifs.rankings.feather' \\\n",
    "--bed_fname '/data2st1/junyi/output/motif/HIP_Neuron_MW_wilcoxon_DAR_lifted.bed' \\\n",
    "--species 'mus_musculus' \\\n",
    "--auc_threshold 0.005 \\\n",
    "--nes_threshold 3.0 \\\n",
    "--rank_threshold 0.05 \\\n",
    "--path_to_motif_annotations '/data2st1/junyi/scenic/mouse/motif/motifs-v10nr_clust-nr.mgi-m0.001-o0.0.tbl' \\\n",
    "--output_folder '/data2st1/junyi/output/motif/' \\\n",
    "--write_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pycistarget cistarget --cistarget_db_fname '/data2st1/junyi/scenic/mouse/motif/mm10_screen_v10_clust.regions_vs_motifs.rankings.feather' \\\n",
    "--bed_fname '/data2st1/junyi/output/motif/AMY_Neuron_MW_wilcoxon_DAR_lifted.bed' \\\n",
    "--species 'mus_musculus' \\\n",
    "--auc_threshold 0.005 \\\n",
    "--nes_threshold 3.0 \\\n",
    "--rank_threshold 0.05 \\\n",
    "--path_to_motif_annotations '/data2st1/junyi/scenic/mouse/motif/motifs-v10nr_clust-nr.mgi-m0.001-o0.0.tbl' \\\n",
    "--output_folder '/data2st1/junyi/output/motif/' \\\n",
    "--write_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pycistarget cistarget --cistarget_db_fname '/data2st1/junyi/scenic/mouse/motif/mm10_screen_v10_clust.regions_vs_motifs.rankings.feather' \\\n",
    "--bed_fname '/data2st1/junyi/output/motif/PFC_Neuron_MW_wilcoxon_DAR_lifted.bed' \\\n",
    "--species 'mus_musculus' \\\n",
    "--auc_threshold 0.005 \\\n",
    "--nes_threshold 3.0 \\\n",
    "--rank_threshold 0.05 \\\n",
    "--path_to_motif_annotations '/data2st1/junyi/scenic/mouse/motif/motifs-v10nr_clust-nr.mgi-m0.001-o0.0.tbl' \\\n",
    "--output_folder '/data2st1/junyi/output/motif/' \\\n",
    "--write_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import copy\n",
    "\n",
    "regions = ['AMY','HIP','PFC']\n",
    "celltypes = ['Neuron']\n",
    "\n",
    "dict_table = {}\n",
    "\n",
    "for region in regions:\n",
    "    for celltype in celltypes:\n",
    "        with h5py.File(f'/data2st1/junyi/output/motif/motif_enrichment_cistarget_{region}_{celltype}_MC_wilcoxon_DAR_lifted.hdf5', 'r') as f:\n",
    "            # Open the HDF5 file\n",
    "            # List all groups and datasets in the file\n",
    "            print(\"Keys in the file:\", list(f.keys()))\n",
    "            \n",
    "\n",
    "            # # Access a specific dataset\n",
    "            expname = f'{region}_{celltype}_MC_wilcoxon_DAR_lifted'\n",
    "            dataset = f[expname]  # Replace with your dataset name\n",
    "            # print(\"Shape of the dataset:\", dataset.shape)\n",
    "            # print(\"Data type of the dataset:\", dataset.dtype)\n",
    "\n",
    "            dict_dataset = {}\n",
    "\n",
    "            #region = f[expname]['motif_hits']['region_set']['metacluster_33.8'][0:10]\n",
    "\n",
    "            table = f[expname]['motif_enrichment']['table'][:]\n",
    "            for key in dataset.keys():\n",
    "                dict_dataset[key] = dataset[key]\n",
    "            # print(\"Data:\", data)\n",
    "            dict_table[expname] = table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dict_table['AMY_Neuron_MC_wilcoxon_DAR_lifted']:\n",
    "    print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_table = {}\n",
    "\n",
    "for region in regions:\n",
    "    for celltype in celltypes:\n",
    "        with h5py.File(f'/data2st1/junyi/output/motif/motif_enrichment_cistarget_{region}_{celltype}_MC_wilcoxon_DAR_lifted.hdf5', 'r') as f:\n",
    "            # Open the HDF5 file\n",
    "            # List all groups and datasets in the file\n",
    "            print(\"Keys in the file:\", list(f.keys()))\n",
    "            \n",
    "\n",
    "            # # Access a specific dataset\n",
    "            expname = f'{region}_{celltype}_MC_wilcoxon_DAR_lifted'\n",
    "            dataset = f[expname]  # Replace with your dataset name\n",
    "            # print(\"Shape of the dataset:\", dataset.shape)\n",
    "            # print(\"Data type of the dataset:\", dataset.dtype)\n",
    "\n",
    "            dict_dataset = {}\n",
    "\n",
    "            region = f[expname]['motif_hits']['region_set']['metacluster_33.8'][:]\n",
    "            region_table[expname] = region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "list_table = []\n",
    "list_key = []\n",
    "\n",
    "for key in dict_table.keys():\n",
    "    data = dict_table[key]\n",
    "    for row in data:\n",
    "        list_table.append(row[0])\n",
    "        list_key.append(key)\n",
    "df_TF = pd.DataFrame({'TF':list_table,'key':list_key})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df_TF.groupby('TF').count().sort_values(by='key',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count[df_count['key']>2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions = pd.DataFrame()\n",
    "\n",
    "for region in regions:\n",
    "    for celltype in celltypes:\n",
    "        with h5py.File(f'/data2st1/junyi/output/motif/motif_enrichment_cistarget_{region}_{celltype}_MC_wilcoxon_DAR_lifted.hdf5', 'r') as f:\n",
    "            # Open the HDF5 file\n",
    "            # List all groups and datasets in the file\n",
    "            print(\"Keys in the file:\", list(f.keys()))\n",
    "            \n",
    "\n",
    "            # # Access a specific dataset\n",
    "            expname = f'{region}_{celltype}_MC_wilcoxon_DAR_lifted'\n",
    "            dataset = f[expname]  # Replace with your dataset name\n",
    "            # print(\"Shape of the dataset:\", dataset.shape)\n",
    "            # print(\"Data type of the dataset:\", dataset.dtype)\n",
    "\n",
    "\n",
    "            for TF in df_count[df_count['key']>2].index:\n",
    "                region = f[expname]['motif_hits']['region_set'][TF][:]\n",
    "                decoded_data = [item.decode('utf-8') for item in region]\n",
    "                df_region = pd.DataFrame(decoded_data,columns=['region'])\n",
    "                df_region['expreiment'] = expname\n",
    "                df_region['TF'] = TF.decode('utf-8')\n",
    "                if len(df_regions)>0:\n",
    "                    df_regions = pd.concat([df_regions,df_region],axis=0,ignore_index=True)\n",
    "                else:\n",
    "                    df_regions = df_region\n",
    "            #region = f[expname]['motif_hits']['region_set']['metacluster_33.8'][:]\n",
    "            #region_table[expname] = df_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count[df_count['key']>2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df_TF, x='key', dodge=False, palette='Set2',)\n",
    "plt.xticks(rotation=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict_table.keys():\n",
    "    print(len(dict_table[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snapatac2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
